# is21 推論パイプライン設計

文書番号: is21_03
作成日: 2025-12-29
ステータス: Draft

---

## 1. パイプライン概要

```
[入力: infer_image]
       ↓
[1. 品質判定] → blur/dark タグ
       ↓
[2. オブジェクト検出] → human/animal/vehicle bbox
       ↓
[3. 属性抽出] → top_color/carry 等
       ↓
[4. primary_event決定]
       ↓
[5. severity計算]
       ↓
[出力: AnalyzeResponse]
```

---

## 2. ステージ1: 品質判定

### 2.1 目的
- 推論精度が低下する画像を早期識別
- camera.blur / camera.dark 等のタグ付与

### 2.2 判定項目
| 項目 | 閾値（案） | タグ |
|-----|----------|------|
| Laplacian分散 | < 100 | camera.blur |
| 平均輝度 | < 30 | camera.dark |
| 最大輝度 | > 250 (80%以上) | camera.glare |

### 2.3 処理フロー
```python
def quality_check(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # blur判定
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
    if laplacian_var < 100:
        tags.append("camera.blur")

    # dark判定
    mean_luma = gray.mean()
    if mean_luma < 30:
        tags.append("camera.dark")

    # glare判定
    glare_ratio = (gray > 250).sum() / gray.size
    if glare_ratio > 0.8:
        tags.append("camera.glare")

    return tags
```

---

## 3. ステージ2: オブジェクト検出

### 3.1 モデル構成（案）
| 用途 | モデル | 入力サイズ | クラス |
|-----|--------|-----------|--------|
| 人物・車両 | YOLOv8n-RKNN | 640x640 | person, car, truck, motorcycle, bicycle |
| 動物 | YOLOv8n-custom | 640x640 | dog, cat, deer, boar, bird |
| 危険物 | YOLOv5s-custom | 640x640 | smoke, fire, water |

### 3.2 検出後処理
```python
def detect_objects(image, model):
    # RKNN推論
    outputs = model.inference(image)

    # NMS
    boxes = nms(outputs, iou_threshold=0.45, conf_threshold=0.25)

    # bbox正規化（0-1）
    normalized = []
    for box in boxes:
        normalized.append({
            "x1": box.x1 / image.width,
            "y1": box.y1 / image.height,
            "x2": box.x2 / image.width,
            "y2": box.y2 / image.height,
            "label": box.label,
            "conf": box.confidence
        })

    return normalized
```

### 3.3 primary_eventマッピング
| 検出クラス | primary_event |
|-----------|---------------|
| person | human |
| dog, cat, deer, boar, bird | animal |
| car, truck, motorcycle, bicycle | vehicle |
| smoke, fire | hazard |
| water | hazard |
| （検出なし） | none |
| （複数カテゴリ混在） | 最高confidenceを優先 |

---

## 4. ステージ3: 属性抽出

### 4.1 top_color（上衣色）
- 人物bboxの上半分を切り出し
- HSV色空間でヒストグラム計算
- 代表色をマッピング

```python
def extract_top_color(image, bbox):
    # 上半分を切り出し
    x1, y1, x2, y2 = bbox
    top_region = image[y1:y1+(y2-y1)//2, x1:x2]

    # HSVでヒストグラム
    hsv = cv2.cvtColor(top_region, cv2.COLOR_BGR2HSV)

    # 代表色判定
    dominant = get_dominant_color(hsv)

    color_map = {
        (0, 20): "red",
        (20, 40): "other",  # orange/yellow
        (40, 80): "other",  # green
        (80, 130): "blue",
        (130, 170): "other", # purple
        (170, 180): "red",
    }

    # 彩度が低い場合
    if saturation < 30:
        if value < 80:
            return "black"
        elif value > 180:
            return "white"
        else:
            return "gray"

    return map_hue_to_color(dominant.hue)
```

### 4.2 carry（持ち物）
- 人物bbox周辺でbackpack/bag検出
- YOLOで検出 or 専用分類器

### 4.3 appearance（外観）
- hat_like: 頭部領域の形状検出
- mask_like: 顔領域の遮蔽検出

---

## 5. ステージ4: primary_event決定

### 5.1 優先順位
1. hazard（火災・浸水等） → 最優先
2. camera_issue（オフライン・画角ズレ） → 次点
3. human → 人物検知
4. animal → 動物検知
5. vehicle → 車両検知
6. none → 検知なし

### 5.2 unknown判定条件
- confidence < 0.5 かつ detected=true
- 複数カテゴリが拮抗（差が0.1未満）
- hazard検出だがconfidence < 0.7

---

## 6. ステージ5: severity計算

### 6.1 基本ルール
| 条件 | severity |
|-----|----------|
| hazard.flame_like, hazard.smoke_like | 3 |
| camera.offline | 3 |
| hazard.water_*, behavior.loitering | 2 |
| camera.moved, camera.occluded | 2 |
| animal.deer, animal.boar | 2 |
| human（深夜帯）※hints_json参照 | 2 |
| その他検知 | 1 |
| 検知なし | 0 |

### 6.2 タグからの自動計算
```python
def calculate_severity(primary_event, tags, schema):
    max_severity = 0
    for tag in tags:
        tag_def = schema.get_tag(tag)
        if tag_def:
            max_severity = max(max_severity, tag_def.severity_default)
    return max_severity
```

---

## 7. 出力生成

### 7.1 AnalyzeResponse構築
```python
def build_response(camera_id, captured_at, schema_version, result):
    return {
        "schema_version": schema_version,
        "camera_id": camera_id,
        "captured_at": captured_at.isoformat(),
        "analyzed": True,
        "detected": result.primary_event != "none",
        "primary_event": result.primary_event,
        "tags": result.tags,
        "confidence": result.max_confidence,
        "severity": result.severity,
        "unknown_flag": result.unknown_flag,
        "count_hint": len([b for b in result.bboxes if b.label == "person"]),
        "bboxes": result.bboxes,
        "processing_ms": result.elapsed_ms,
        "model_info": {
            "name": result.model_name,
            "version": result.model_version
        }
    }
```

---

## 8. パフォーマンス目標

| 処理 | 目標時間 | 備考 |
|-----|---------|------|
| 画像デコード | 10ms | JPEG→numpy |
| 品質判定 | 5ms | OpenCV |
| オブジェクト検出 | 200ms | RKNN推論 |
| 属性抽出 | 50ms | 色判定等 |
| レスポンス生成 | 5ms | JSON構築 |
| **合計** | **< 300ms** | 640px画像 |

---

## 9. テスト観点

### 9.1 品質判定
- [ ] ブレ画像でcamera.blurが付く
- [ ] 暗い画像でcamera.darkが付く
- [ ] 正常画像で品質タグなし

### 9.2 検出精度
- [ ] 人物1名でhuman + count.single
- [ ] 人物複数でhuman + count.multiple
- [ ] 動物でanimal + animal.{種類}
- [ ] 何もない画像でnone

### 9.3 属性抽出
- [ ] 赤いシャツでtop_color.red
- [ ] リュックでcarry.backpack
- [ ] 帽子でappearance.hat_like

### 9.4 severity
- [ ] 煙検知でseverity=3
- [ ] 通常人物検知でseverity=1
- [ ] 検知なしでseverity=0
